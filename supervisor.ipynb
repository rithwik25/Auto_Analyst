{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#supervisor routes b/w different independant agents\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "def _set_if_undefined(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"Please provide your {var}\")\n",
    "\n",
    "\n",
    "_set_if_undefined(\"OPENAI_API_KEY\") \n",
    "_set_if_undefined(\"LANGCHAIN_API_KEY\") \n",
    "#_set_if_undefined(\"TAVILY_API_KEY\")\n",
    "\n",
    "# Optional, add tracing in LangSmith\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Agent supervisor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Years of Experience</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>5.0</td>\n",
       "      <td>90000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>3.0</td>\n",
       "      <td>65000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Senior Manager</td>\n",
       "      <td>15.0</td>\n",
       "      <td>150000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Sales Associate</td>\n",
       "      <td>7.0</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Director</td>\n",
       "      <td>20.0</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Gender Education Level          Job Title  Years of Experience  \\\n",
       "0  32.0    Male      Bachelor's  Software Engineer                  5.0   \n",
       "1  28.0  Female        Master's       Data Analyst                  3.0   \n",
       "2  45.0    Male             PhD     Senior Manager                 15.0   \n",
       "3  36.0  Female      Bachelor's    Sales Associate                  7.0   \n",
       "4  52.0    Male        Master's           Director                 20.0   \n",
       "\n",
       "     Salary  \n",
       "0   90000.0  \n",
       "1   65000.0  \n",
       "2  150000.0  \n",
       "3   60000.0  \n",
       "4  200000.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools.sql_database.tool import (\n",
    "    InfoSQLDatabaseTool,\n",
    "    ListSQLDatabaseTool,\n",
    "    QuerySQLCheckerTool,\n",
    "    QuerySQLDataBaseTool,\n",
    ")\n",
    "df = pd.read_csv(\"salary_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connection = sqlite3.connect(\"salaries.db\")\n",
    "#df.to_sql(name=\"salaries\", con=connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "db = SQLDatabase.from_uri(\"sqlite:///salaries.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Tools\n",
    "For this example, you will make an agent to do web research with a search engine, and one agent to create plots. Define the tools they'll use below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "\n",
    "#tavily_tool = TavilySearchResults(max_results=5)\n",
    "\n",
    "# This executes code locally, which can be unsafe\n",
    "#python_repl_tool = PythonREPLTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Utilities\n",
    "Define a helper function below, which make it easier to add new agent worker nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.messages import (\n",
    "    BaseMessage,\n",
    "    HumanMessage,\n",
    "    ToolMessage,\n",
    ")\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "def create_agent(llm: AzureChatOpenAI, tools: list, system_prompt: str):\n",
    "    # Each worker node will be given a name and some tools.\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                system_prompt,\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        ]\n",
    "    )\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools, handle_parsing_errors=True)\n",
    "    return executor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also define a function that we will use to be the nodes in the graph - it takes care of converting the agent response to a human message. This is important because that is how we will add it to the global state of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Agent Supervisor\n",
    "It will use function calling to choose the next worker node OR finish processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "members = [\"sql_developer\", \"chart_generator\"]\n",
    "system_prompt = (\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \" following workers:  {members}. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. When finished,\"\n",
    "    \" respond with FINISH.\"\n",
    ")\n",
    "# Our team supervisor is an LLM node. It just picks the next agent to process\n",
    "# and decides when the work is completed\n",
    "options = [\"FINISH\"] + members\n",
    "# Using openai function calling can make output parsing easier for us\n",
    "function_def = {\n",
    "    \"name\": \"route\",\n",
    "    \"description\": \"Select the next role.\",\n",
    "    \"parameters\": {\n",
    "        \"title\": \"routeSchema\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"next\": {\n",
    "                \"title\": \"Next\",\n",
    "                \"anyOf\": [\n",
    "                    {\"enum\": options},\n",
    "                ],\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"next\"],\n",
    "    },\n",
    "}\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given the conversation above, who should act next?\"\n",
    "            \" Or should we FINISH? Select one of: {options}\",\n",
    "        ),\n",
    "    ]\n",
    ").partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "llm = AzureChatOpenAI(model=\"model\", openai_api_key = \"your_openai_api_key\", \n",
    "                    openai_api_type=\"type\", \n",
    "                    azure_endpoint=\"endpoint\",\n",
    "                    api_version=\"version\")\n",
    "\n",
    "supervisor_chain = (\n",
    "    prompt\n",
    "    | llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
    "    | JsonOutputFunctionsParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "#tavily_tool = TavilySearchResults(max_results=5)\n",
    "\n",
    "# Warning: This executes code locally, which can be unsafe when not sandboxed\n",
    "\n",
    "repl = PythonREPL()\n",
    "\n",
    "@tool\n",
    "def python_repl( # A python tool which can run python code.\n",
    "    code: Annotated[str, \"The python code to execute to generate your chart.\"],\n",
    "):\n",
    "    \"\"\"Use this to execute python code. If you want to see the output of a value,\n",
    "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
    "    try:\n",
    "        result = repl.run(code)\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute. Error: {repr(e)}\"\n",
    "    result_str = f\"Successfully executed:\\n```python\\n{code}\\n```\\nStdout: {result}\"\n",
    "    return (\n",
    "        result_str + \"\\n\\nIf you have completed all tasks, respond with FINAL ANSWER.\"\n",
    "    )\n",
    "\n",
    "@tool(\"list_tables\")\n",
    "def list_tables() -> str:\n",
    "    \"\"\"List the available tables in the database\"\"\"\n",
    "    return ListSQLDatabaseTool(db=db).invoke(\"\")\n",
    "\n",
    "@tool(\"tables_schema\")\n",
    "def tables_schema(tables: str) -> str:\n",
    "    \"\"\"\n",
    "    Input is a comma-separated list of tables, output is the schema and sample rows\n",
    "    for those tables. Be sure that the tables actually exist by calling `list_tables` first!\n",
    "    Example Input: table1, table2, table3\n",
    "    \"\"\"\n",
    "    tool = InfoSQLDatabaseTool(db=db)\n",
    "    return tool.invoke(tables)\n",
    "\n",
    "@tool(\"execute_sql\")\n",
    "def execute_sql(sql_query: str) -> str:\n",
    "    \"\"\"Execute a SQL query against the database. Returns the result\"\"\"\n",
    "    return QuerySQLDataBaseTool(db=db).invoke(sql_query)\n",
    "\n",
    "@tool(\"check_sql\")\n",
    "def check_sql(sql_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Use this tool to double check if your query is correct before executing it. Always use this\n",
    "    tool before executing a query with `execute_sql`.\n",
    "    \"\"\"\n",
    "    return QuerySQLCheckerTool(db=db, llm=llm).invoke({\"query\": sql_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2c43c696c80>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import functools\n",
    "import operator\n",
    "from typing import Sequence, TypedDict\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "\n",
    "# The agent state is the input to each node in the graph\n",
    "class AgentState(TypedDict):\n",
    "    # The annotation tells the graph that new messages will always\n",
    "    # be added to the current states\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    # The 'next' field indicates where to route to next\n",
    "    next: str\n",
    "\n",
    "#sql developer\n",
    "sql_dev = create_agent(llm, \n",
    "                       tools=[list_tables, tables_schema, check_sql, execute_sql], \n",
    "                       system_prompt=\"\"\" \n",
    "                        You are an experienced database engineer who is master at creating efficient and complex SQL queries. \n",
    "                        You have a deep understanding of how different databases work and how to optimize queries. \n",
    "                        Use the `list_tables` to find available tables. \n",
    "                        Use the `tables_schema` to understand the metadata for the tables. \n",
    "                        Use the `check_sql` to check your queries for correctness. \n",
    "                        Use the `execute_sql` to execute queries against the database.\n",
    "                        Your main goal is to construct and execute sql queries based on a request    \n",
    "                        \"\"\")\n",
    "sql_dev_node = functools.partial(agent_node, agent = sql_dev, name=\"sql_developer\")\n",
    "\n",
    "# chart_generator\n",
    "chart_generator = create_agent(\n",
    "    llm,\n",
    "    tools = [python_repl],\n",
    "    system_prompt= \"\"\" \n",
    "                    You are a helpful AI assistant expert that writes and executes Python scripts to visualize data in a dataframe.\n",
    "                    Analyze the dataframe given to you carefully and write a script to visualize the data as asked by the user, then execute the script.\n",
    "                    Import the necessary libraries for plotting. Return the path to the saved image as answer. \n",
    "                    The final answer should not have a parse-able action.\n",
    "                    Use the 'python_repl' to execute a python script.\n",
    "                    Before using plt.show(), save the image using plt.savefig('img.png').\n",
    "                    If you encounter errors multiple times, try changing the approach.\n",
    "                    Close the plot with plt.close(). Return the path of the saved image in answer.\n",
    "                    If the user does not request for a pie chart or bar chart or scatter plot, then don't do anything. \n",
    "                    \"\"\",\n",
    ")\n",
    "\n",
    "# summary_writer\n",
    "summary_writer = create_agent(\n",
    "    llm,\n",
    "    tools = [],\n",
    "    system_prompt=\"You are a summary writer. Your task is to provide concise and accurate summaries.\"\n",
    ")\n",
    "\n",
    "chart_node = functools.partial(agent_node, agent = chart_generator, name=\"chart_generator\")\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"sql_developer\", sql_dev_node)\n",
    "workflow.add_node(\"chart_generator\", chart_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for member in members:\n",
    "    # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "# The supervisor populates the \"next\" field in the graph state\n",
    "# which routes to a node or finishes\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "# Finally, add entrypoint\n",
    "workflow.add_edge(START, \"supervisor\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'sql_developer'}}\n",
      "----\n",
      "{'sql_developer': {'messages': [HumanMessage(content='The number of employees doing the job of a Data Scientist is 453.', additional_kwargs={}, response_metadata={}, name='sql_developer')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'FINISH'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for s in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"What are the number of employees doing data scientist job?\")\n",
    "        ]\n",
    "    }\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'sql_developer'}}\n",
      "----\n",
      "{'sql_developer': {'messages': [HumanMessage(content='Here is the data showing the average salary by years of experience:\\n\\n| Years of Experience | Average Salary       |\\n|---------------------|----------------------|\\n| 0.0                 | 29680.23             |\\n| 0.5                 | 35000.00             |\\n| 1.0                 | 46992.85             |\\n| 1.5                 | 36279.17             |\\n| 2.0                 | 58699.46             |\\n| 3.0                 | 72944.41             |\\n| 4.0                 | 83332.09             |\\n| 5.0                 | 103111.09            |\\n| 6.0                 | 111891.15            |\\n| 7.0                 | 122108.23            |\\n| 8.0                 | 126438.14            |\\n| 9.0                 | 138021.46            |\\n| 10.0                | 131690.32            |\\n| 11.0                | 153060.32            |\\n| 12.0                | 153398.06            |\\n| 13.0                | 153002.18            |\\n| 14.0                | 168632.36            |\\n| 15.0                | 160664.76            |\\n| 16.0                | 183285.44            |\\n| 17.0                | 184053.83            |\\n| 18.0                | 184340.41            |\\n| 19.0                | 182430.33            |\\n| 20.0                | 182288.72            |\\n| 21.0                | 176734.19            |\\n| 22.0                | 188644.53            |\\n| 23.0                | 189573.70            |\\n| 24.0                | 211225.42            |\\n| 25.0                | 177803.46            |\\n| 26.0                | 187717.29            |\\n| 27.0                | 187922.64            |\\n| 28.0                | 189774.81            |\\n| 29.0                | 181437.00            |\\n| 30.0                | 163339.83            |\\n| 31.0                | 183027.20            |\\n| 32.0                | 192540.80            |\\n| 33.0                | 186400.67            |\\n| 34.0                | 188651.00            |\\n\\nYou can use this data to draw the bar chart showing the effect of salary on employee experience.', additional_kwargs={}, response_metadata={}, name='sql_developer')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'chart_generator'}}\n",
      "----\n",
      "{'chart_generator': {'messages': [HumanMessage(content='The bar chart showing the effect of salary on employee experience has been created and saved. \\n\\nThe image can be found at the following path: `img.png`.', additional_kwargs={}, response_metadata={}, name='chart_generator')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'FINISH'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for s in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Draw a bar chart showing the effect of salary on employee experience\")\n",
    "        ]\n",
    "    }\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
